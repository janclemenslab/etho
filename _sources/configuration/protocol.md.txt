# Experimental protocols
For experiment-specific settings.

### Make
[yaml](pyyaml.org) format. The following fields are supported:
```yaml
user: USER  # OPTIONAL - default user set in ethoconfig.yml
savefolder: C:/Users/USER/data # OPTIONAL - default set in ethoconfig.yml - this is where the recordings will be saved
maxduration: 90 # seconds
use_services: [GCM, DAQ]  # list services by their 3-letter abbreviations. only these will be run! See service-specific parameters below for valid names
serializer: pickle  # save default
python_exe: C:/miniconda/envs/etho/python.exe   # OPTIONAL - default set in ethoconfig.yml - run this prot in specific env
```

```yaml
# SERVICE specific parameters
GCM:  # generic camera interface with different backends   cam_type: Ximea  # or Spinnaker or FlyCapture2
  frame_rate: 100.0  # frames per second
  frame_width: 640  # pixels
  frame_height: 200  # pixels
  shutter_speed: 5_000 # us=5ms
  frame_offx: 78  # pixels
  frame_offy: 10  # pixels
  brightness: 0.0 # OPTIONAL
  exposure: 0.0  # OPTIONAL
  gamma: 1.0  # OPTIONAL
  gain: 0.0
  cam_serialnumber: 30959651  # MQ013CG-ON
  binning: 1  # set horz and vert binning - typically, 1, 2, 4 is available
  optimize_auto_exposure: True  # defaults to False
  external_trigger: False #
  host:  # individual services can run on specific hosts
    name: 192.168.1.42
    user: ncb
    python_exe: C:/miniconda/envs/etho/python.exe
    savefolder: C:/Users/ncb/data
  callbacks:
    save_avi:  # save frames as avi using opencv VideoWriter (has no params)
    save_avi_vidread:  # save frames as avi using VidRead
      ffmpeg_params:  # configure ffmpeg backend - need to prepend `-` to each param
        -crf: 16
    save_avi_fast:  # or save frames as avi using Nvidia's GPU-based VideoProcessingFramework
      VPF_bin_path: C:/Users/ncb/vpf/bin3.7  # path to the directory containing the binaries for VPF
    save_timestamps:  # save timestamps for each frame to h5 file
    disp:  # plot frames using opencv
    disp_fast:  # plot frames using pyqtgraph (faster?)

DAQ:
  clock_source: OnboardClock
  samplingrate: 5000 # Hz
  shuffle: True # block-randomize order of stimuli for playback
  ledamp: 1.0
  analog_chans_in: [ai0]
  analog_chans_out: [ao0, ao1]
  callbacks:
    save_h5:   # save data as hdfs (has no params)
    plot:  # plot traces using matplotlib OR
    plot_fast:  # plot traces using pyqtgraph (much faster!) (use either `plot` or plot_fast`, never both)


DAQ:
  clock_source: OnboardClock
  samplingrate: 10000 # Hz
  shuffle: True # block-randomize order of stimuli for playback
  device: Dev1
  analog_chans_in: [ai0:8, ai9, ai10]
  analog_chans_in_limits: [[0, 5], [0, 10], [-10, 10]] # or "10"
  analog_chans_in_terminal: [RSE, NRSE, Diff]  # defaults to RSE
  analog_chans_out: [ao0, ao1]
  analog_chans_out_limits: [10, 10]
  digital_chans_out: [...]
  callbacks:
    save_h5:   # save data as hdfs (has no params)
    plot:  # plot traces using matplotlib OR
    plot_fast:  # plot traces using pyqtgraph (much faster!) (use either `plot` or plot_fast`, never both)

THUA:
  pin ???

CAM:  # pi camera
  framerate: 30 # frames per second
  framewidth: 1000 # pixels
  frameheight: 1000 # pixels
  shutterspeed: 10000 # ns=10ms
  annotate_frame_num: False # print frame number in each frame
  # currently unused picamera options but probably useful
  exposuremode: 'fixedfps'
  video_denoise: False

THU: # pi temperature and humidity sensor
  pin: 17 # GPIO PIN for read out
  interval: 20 # seconds, log temperature and humidity every 20 seconds

OPT2:  # pi opto led control
  pin: [25, 24]  # red and green led channel
  playlist_channels: [2, 3]

SND:  # pi sound playback via pygame
  samplingrate: 44100  # Hz
  shuffle: False  # block-randomize order of stimuli for playback
  ledamp: 1300  # amplitude of the IR LED used for syncing audio and video
  playlist_channels: [0, 1]

REL:  # pi relay control (for backlight and illumination)
  pin: 22

DLP:  # DLP projector
  warpfile: 'Z:/#Data/flyball/projector/warpmesh_1140x912.data'
  use_warping: False
  callbacks:
    savedlp_h5:  # save per-frame stimulus parameters to `_dlp.h5`
  runners:
    LED_blinker:
      object: 'Rect'  # should be the classname: `psychopy.visuals.NAME`
      led_frame: 360
      led_duration: 180
```

### Parse
```python
from ethomaster.utils.config import readconfig
prot = readconfig(protocolfile)
```
